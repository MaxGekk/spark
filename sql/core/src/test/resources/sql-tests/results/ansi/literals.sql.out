-- Automatically generated by SQLQueryTestSuite
-- !query
select null, Null, nUll
-- !query schema
struct<null:void,Null:void,nUll:void>
-- !query output
NULL	NULL	NULL


-- !query
select true, tRue, false, fALse
-- !query schema
struct<true:boolean,tRue:boolean,false:boolean,fALse:boolean>
-- !query output
true	true	false	false


-- !query
select 1Y
-- !query schema
struct<1Y:tinyint>
-- !query output
1


-- !query
select 127Y, -128Y
-- !query schema
struct<127Y:tinyint,- 128Y:tinyint>
-- !query output
127	-128


-- !query
select 128Y
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0023",
  "messageParameters" : {
    "maxValue" : "127",
    "minValue" : "-128",
    "rawStrippedQualifier" : "128",
    "typeName" : "tinyint"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 11,
    "fragment" : "128Y"
  } ]
}


-- !query
select 1S
-- !query schema
struct<1S:smallint>
-- !query output
1


-- !query
select 32767S, -32768S
-- !query schema
struct<32767S:smallint,- 32768S:smallint>
-- !query output
32767	-32768


-- !query
select 32768S
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0023",
  "messageParameters" : {
    "maxValue" : "32767",
    "minValue" : "-32768",
    "rawStrippedQualifier" : "32768",
    "typeName" : "smallint"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 13,
    "fragment" : "32768S"
  } ]
}


-- !query
select 1L, 2147483648L
-- !query schema
struct<1L:bigint,2147483648L:bigint>
-- !query output
1	2147483648


-- !query
select 9223372036854775807L, -9223372036854775808L
-- !query schema
struct<9223372036854775807L:bigint,- 9223372036854775808L:bigint>
-- !query output
9223372036854775807	-9223372036854775808


-- !query
select 9223372036854775808L
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0023",
  "messageParameters" : {
    "maxValue" : "9223372036854775807",
    "minValue" : "-9223372036854775808",
    "rawStrippedQualifier" : "9223372036854775808",
    "typeName" : "bigint"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 27,
    "fragment" : "9223372036854775808L"
  } ]
}


-- !query
select 1, -1
-- !query schema
struct<1:int,- 1:int>
-- !query output
1	-1


-- !query
select 2147483647, -2147483648
-- !query schema
struct<2147483647:int,- 2147483648:int>
-- !query output
2147483647	-2147483648


-- !query
select 9223372036854775807, -9223372036854775808
-- !query schema
struct<9223372036854775807:bigint,- 9223372036854775808:bigint>
-- !query output
9223372036854775807	-9223372036854775808


-- !query
select 9223372036854775808, -9223372036854775809
-- !query schema
struct<9223372036854775808:decimal(19,0),- 9223372036854775809:decimal(19,0)>
-- !query output
9223372036854775808	-9223372036854775809


-- !query
select 1234567890123456789012345678901234567890
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_1229",
  "messageParameters" : {
    "decimalType" : "decimal",
    "precision" : "38"
  }
}


-- !query
select 1234567890123456789012345678901234567890.0
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_1229",
  "messageParameters" : {
    "decimalType" : "decimal",
    "precision" : "38"
  }
}


-- !query
select 1F, 1.2F, .10f, 0.10f
-- !query schema
struct<1F:float,1.2F:float,.10f:float,0.10f:float>
-- !query output
1.0	1.2	0.1	0.1


-- !query
select -1F, -1.2F, -.10F, -0.10F
-- !query schema
struct<- 1F:float,- 1.2F:float,- .10F:float,- 0.10F:float>
-- !query output
-1.0	-1.2	-0.1	-0.1


-- !query
select -3.4028235E39f
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0023",
  "messageParameters" : {
    "maxValue" : "3.4028234663852886E+38",
    "minValue" : "-3.4028234663852886E+38",
    "rawStrippedQualifier" : "-3.4028235E39",
    "typeName" : "float"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 21,
    "fragment" : "-3.4028235E39f"
  } ]
}


-- !query
select 1D, 1.2D, 1e10, 1.5e5, .10D, 0.10D, .1e5, .9e+2, 0.9e+2, 900e-1, 9.e+1
-- !query schema
struct<1D:double,1.2D:double,1e10:double,1.5e5:double,.10D:double,0.10D:double,.1e5:double,.9e+2:double,0.9e+2:double,900e-1:double,9.e+1:double>
-- !query output
1.0	1.2	1.0E10	150000.0	0.1	0.1	10000.0	90.0	90.0	90.0	90.0


-- !query
select -1D, -1.2D, -1e10, -1.5e5, -.10D, -0.10D, -.1e5
-- !query schema
struct<- 1D:double,- 1.2D:double,- 1e10:double,- 1.5e5:double,- .10D:double,- 0.10D:double,- .1e5:double>
-- !query output
-1.0	-1.2	-1.0E10	-150000.0	-0.1	-0.1	-10000.0


-- !query
select .e3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "PARSE_SYNTAX_ERROR",
  "sqlState" : "42601",
  "messageParameters" : {
    "error" : "'.'",
    "hint" : ""
  }
}


-- !query
select 1E309, -1E309
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0023",
  "messageParameters" : {
    "maxValue" : "1.7976931348623157E+308",
    "minValue" : "-1.7976931348623157E+308",
    "rawStrippedQualifier" : "1E309",
    "typeName" : "double"
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 12,
    "fragment" : "1E309"
  } ]
}


-- !query
select 0.3, -0.8, .5, -.18, 0.1111, .1111
-- !query schema
struct<0.3:decimal(1,1),- 0.8:decimal(1,1),.5:decimal(1,1),- .18:decimal(2,2),0.1111:decimal(4,4),.1111:decimal(4,4)>
-- !query output
0.3	-0.8	0.5	-0.18	0.1111	0.1111


-- !query
select 0.3 F, 0.4 D, 0.5 BD
-- !query schema
struct<F:decimal(1,1),D:decimal(1,1),BD:decimal(1,1)>
-- !query output
0.3	0.4	0.5


-- !query
select 123456789012345678901234567890123456789e10d, 123456789012345678901234567890123456789.1e10d
-- !query schema
struct<123456789012345678901234567890123456789e10d:double,123456789012345678901234567890123456789.1e10d:double>
-- !query output
1.2345678901234568E48	1.2345678901234568E48


-- !query
select "Hello Peter!", 'hello lee!'
-- !query schema
struct<"Hello Peter!":string,'hello lee!':string>
-- !query output
Hello Peter!	hello lee!


-- !query
select 'hello' 'world', 'hello' " " 'lee'
-- !query schema
struct<'hello' 'world':string,'hello' " " 'lee':string>
-- !query output
helloworld	hello lee


-- !query
select "hello 'peter'"
-- !query schema
struct<"hello 'peter'":string>
-- !query output
hello 'peter'


-- !query
select 'pattern%', 'no-pattern\%', 'pattern\\%', 'pattern\\\%'
-- !query schema
struct<'pattern%':string,'no-pattern\%':string,'pattern\\%':string,'pattern\\\%':string>
-- !query output
pattern%	no-pattern\%	pattern\%	pattern\\%


-- !query
select '\'', '"', '\n', '\r', '\t', 'Z'
-- !query schema
struct<'\'':string,'"':string,'\n':string,'\r':string,'\t':string,'Z':string>
-- !query output
'	"	
				Z


-- !query
select '\110\145\154\154\157\041'
-- !query schema
struct<'\110\145\154\154\157\041':string>
-- !query output
Hello!


-- !query
select '\u0057\u006F\u0072\u006C\u0064\u0020\u003A\u0029'
-- !query schema
struct<'\u0057\u006F\u0072\u006C\u0064\u0020\u003A\u0029':string>
-- !query output
World :)


-- !query
select dAte '2016-03-12'
-- !query schema
struct<dAte '2016-03-12':date>
-- !query output
2016-03-12


-- !query
select date 'mar 11 2016'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_TYPED_LITERAL",
  "sqlState" : "42604",
  "messageParameters" : {
    "value" : "'mar 11 2016'",
    "valueType" : "\"DATE\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 25,
    "fragment" : "date 'mar 11 2016'"
  } ]
}


-- !query
select tImEstAmp '2016-03-11 20:54:00.000'
-- !query schema
struct<tImEstAmp '2016-03-11 20:54:00.000':timestamp>
-- !query output
2016-03-11 20:54:00


-- !query
select timestamp '2016-33-11 20:54:00.000'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_TYPED_LITERAL",
  "sqlState" : "42604",
  "messageParameters" : {
    "value" : "'2016-33-11 20:54:00.000'",
    "valueType" : "\"TIMESTAMP\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 42,
    "fragment" : "timestamp '2016-33-11 20:54:00.000'"
  } ]
}


-- !query
select GEO '(10,-6)'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "UNSUPPORTED_TYPED_LITERAL",
  "sqlState" : "0A000",
  "messageParameters" : {
    "supportedTypes" : "\"DATE\", \"TIMESTAMP_NTZ\", \"TIMESTAMP_LTZ\", \"TIMESTAMP\", \"INTERVAL\", \"X\"",
    "unsupportedType" : "\"GEO\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 20,
    "fragment" : "GEO '(10,-6)'"
  } ]
}


-- !query
select 90912830918230182310293801923652346786BD, 123.0E-28BD, 123.08BD
-- !query schema
struct<90912830918230182310293801923652346786BD:decimal(38,0),123.0E-28BD:decimal(29,29),123.08BD:decimal(5,2)>
-- !query output
90912830918230182310293801923652346786	0.00000000000000000000000001230	123.08


-- !query
select 1.20E-38BD
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "_LEGACY_ERROR_TEMP_0061",
  "messageParameters" : {
    "msg" : "decimal can only support precision up to 38."
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 17,
    "fragment" : "1.20E-38BD"
  } ]
}


-- !query
select x'2379ACFe'
-- !query schema
struct<x '2379ACFe':binary>
-- !query output
#y��


-- !query
select X'XuZ'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.catalyst.parser.ParseException
{
  "errorClass" : "INVALID_TYPED_LITERAL",
  "sqlState" : "42604",
  "messageParameters" : {
    "value" : "'XuZ'",
    "valueType" : "\"X\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 13,
    "fragment" : "X'XuZ'"
  } ]
}


-- !query
SELECT 3.14, -3.14, 3.14e8, 3.14e-8, -3.14e8, -3.14e-8, 3.14e+8, 3.14E8, 3.14E-8
-- !query schema
struct<3.14:decimal(3,2),- 3.14:decimal(3,2),3.14e8:double,3.14e-8:double,- 3.14e8:double,- 3.14e-8:double,3.14e+8:double,3.14E8:double,3.14E-8:double>
-- !query output
3.14	-3.14	3.14E8	3.14E-8	-3.14E8	-3.14E-8	3.14E8	3.14E8	3.14E-8


-- !query
select +date '1999-01-01'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"DATE '1999-01-01'\"",
    "inputType" : "\"DATE\"",
    "paramIndex" : "1",
    "requiredType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(+ DATE '1999-01-01')\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 25,
    "fragment" : "+date '1999-01-01'"
  } ]
}


-- !query
select +timestamp '1999-01-01'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"TIMESTAMP '1999-01-01 00:00:00'\"",
    "inputType" : "\"TIMESTAMP\"",
    "paramIndex" : "1",
    "requiredType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(+ TIMESTAMP '1999-01-01 00:00:00')\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "+timestamp '1999-01-01'"
  } ]
}


-- !query
select +interval '1 day'
-- !query schema
struct<+ interval '1 day':interval day>
-- !query output
1 00:00:00.000000000


-- !query
select +map(1, 2)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"map(1, 2)\"",
    "inputType" : "\"MAP<INT, INT>\"",
    "paramIndex" : "1",
    "requiredType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(+ map(1, 2))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 17,
    "fragment" : "+map(1, 2)"
  } ]
}


-- !query
select +array(1,2)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"array(1, 2)\"",
    "inputType" : "\"ARRAY<INT>\"",
    "paramIndex" : "1",
    "requiredType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(+ array(1, 2))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 18,
    "fragment" : "+array(1,2)"
  } ]
}


-- !query
select +named_struct('a', 1, 'b', 'spark')
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"named_struct(a, 1, b, spark)\"",
    "inputType" : "\"STRUCT<a: INT, b: STRING>\"",
    "paramIndex" : "1",
    "requiredType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(+ named_struct(a, 1, b, spark))\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 42,
    "fragment" : "+named_struct('a', 1, 'b', 'spark')"
  } ]
}


-- !query
select +X'1'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"X'01'\"",
    "inputType" : "\"BINARY\"",
    "paramIndex" : "1",
    "requiredType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(+ X'01')\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 12,
    "fragment" : "+X'1'"
  } ]
}


-- !query
select -date '1999-01-01'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"DATE '1999-01-01'\"",
    "inputType" : "\"DATE\"",
    "paramIndex" : "1",
    "requiredType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(- DATE '1999-01-01')\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 25,
    "fragment" : "-date '1999-01-01'"
  } ]
}


-- !query
select -timestamp '1999-01-01'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"TIMESTAMP '1999-01-01 00:00:00'\"",
    "inputType" : "\"TIMESTAMP\"",
    "paramIndex" : "1",
    "requiredType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(- TIMESTAMP '1999-01-01 00:00:00')\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 30,
    "fragment" : "-timestamp '1999-01-01'"
  } ]
}


-- !query
select -x'2379ACFe'
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
  "sqlState" : "42K09",
  "messageParameters" : {
    "inputSql" : "\"X'2379ACFE'\"",
    "inputType" : "\"BINARY\"",
    "paramIndex" : "1",
    "requiredType" : "(\"NUMERIC\" or \"INTERVAL DAY TO SECOND\" or \"INTERVAL YEAR TO MONTH\" or \"INTERVAL\")",
    "sqlExpr" : "\"(- X'2379ACFE')\""
  },
  "queryContext" : [ {
    "objectType" : "",
    "objectName" : "",
    "startIndex" : 8,
    "stopIndex" : 19,
    "fragment" : "-x'2379ACFe'"
  } ]
}
