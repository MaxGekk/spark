-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE TEMPORARY VIEW t1 AS SELECT * FROM VALUES
  (1, 2, 3)
AS t1(t1a, t1b, t1c)
-- !query schema
struct<>
-- !query output



-- !query
CREATE TEMPORARY VIEW t2 AS SELECT * FROM VALUES
  (1, 0, 1)
AS t2(t2a, t2b, t2c)
-- !query schema
struct<>
-- !query output



-- !query
CREATE TEMPORARY VIEW t3 AS SELECT * FROM VALUES
  (3, 1, 2)
AS t3(t3a, t3b, t3c)
-- !query schema
struct<>
-- !query output



-- !query
CREATE TEMPORARY VIEW t4 AS SELECT * FROM VALUES
  (CAST(1 AS DOUBLE), CAST(2 AS STRING), CAST(3 AS STRING))
AS t1(t4a, t4b, t4c)
-- !query schema
struct<>
-- !query output



-- !query
CREATE TEMPORARY VIEW t5 AS SELECT * FROM VALUES
  (CAST('2011-01-01 01:01:01' AS TIMESTAMP), CAST(2 AS STRING), CAST(3 AS BIGINT))
AS t1(t5a, t5b, t5c)
-- !query schema
struct<>
-- !query output



-- !query
SELECT 
  ( SELECT max(t2b), min(t2b) 
    FROM t2 
    WHERE t2.t2b = t1.t1b
    GROUP BY t2.t2b
  )
FROM t1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{"errorClass":"legacy","messageParameters":["Scalar subquery must return only one column, but got 2"],"queryContext":[]}


-- !query
SELECT 
  ( SELECT max(t2b), min(t2b) 
    FROM t2 
    WHERE t2.t2b > 0
    GROUP BY t2.t2b
  )
FROM t1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{"errorClass":"legacy","messageParameters":["Scalar subquery must return only one column, but got 2"],"queryContext":[]}


-- !query
SELECT * FROM t1
WHERE
t1a IN (SELECT t2a, t2b 
        FROM t2
        WHERE t1a = t2a)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{"errorClass":"legacy","messageParameters":["cannot resolve '(t1.t1a IN (listquery(t1.t1a)))' due to data type mismatch: \nThe number of columns in the left hand side of an IN subquery does not match the\nnumber of columns in the output of subquery.\n#columns in left hand side: 1.\n#columns in right hand side: 2.\nLeft side columns:\n[t1.t1a].\nRight side columns:\n[t2.t2a, t2.t2b].; line 3 pos 4"],"queryContext":[]}


-- !query
SELECT * FROM T1 
WHERE
(t1a, t1b) IN (SELECT t2a
               FROM t2
               WHERE t1a = t2a)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{"errorClass":"legacy","messageParameters":["cannot resolve '(named_struct('t1a', t1.t1a, 't1b', t1.t1b) IN (listquery(t1.t1a)))' due to data type mismatch: \nThe number of columns in the left hand side of an IN subquery does not match the\nnumber of columns in the output of subquery.\n#columns in left hand side: 2.\n#columns in right hand side: 1.\nLeft side columns:\n[t1.t1a, t1.t1b].\nRight side columns:\n[t2.t2a].; line 3 pos 11"],"queryContext":[]}


-- !query
SELECT * FROM t4
WHERE
(t4a, t4b, t4c) IN (SELECT t5a,
                           t5b,
                           t5c
                    FROM t5)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{"errorClass":"legacy","messageParameters":["cannot resolve '(named_struct('t4a', t4.t4a, 't4b', t4.t4b, 't4c', t4.t4c) IN (listquery()))' due to data type mismatch: \nThe data type of one or more elements in the left hand side of an IN subquery\nis not compatible with the data type of the output of the subquery\nMismatched columns:\n[(t4.t4a:double, t5.t5a:timestamp), (t4.t4c:string, t5.t5c:bigint)]\nLeft side:\n[double, string, string].\nRight side:\n[timestamp, string, bigint].; line 3 pos 16"],"queryContext":[]}
