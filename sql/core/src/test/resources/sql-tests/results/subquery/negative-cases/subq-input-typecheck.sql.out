-- Automatically generated by SQLQueryTestSuite
-- !query
CREATE TEMPORARY VIEW t1 AS SELECT * FROM VALUES
  (1, 2, 3)
AS t1(t1a, t1b, t1c)
-- !query schema
struct<>
-- !query output



-- !query
CREATE TEMPORARY VIEW t2 AS SELECT * FROM VALUES
  (1, 0, 1)
AS t2(t2a, t2b, t2c)
-- !query schema
struct<>
-- !query output



-- !query
CREATE TEMPORARY VIEW t3 AS SELECT * FROM VALUES
  (3, 1, 2)
AS t3(t3a, t3b, t3c)
-- !query schema
struct<>
-- !query output



-- !query
CREATE TEMPORARY VIEW t4 AS SELECT * FROM VALUES
  (CAST(1 AS DOUBLE), CAST(2 AS STRING), CAST(3 AS STRING))
AS t1(t4a, t4b, t4c)
-- !query schema
struct<>
-- !query output



-- !query
CREATE TEMPORARY VIEW t5 AS SELECT * FROM VALUES
  (CAST('2011-01-01 01:01:01' AS TIMESTAMP), CAST(2 AS STRING), CAST(3 AS BIGINT))
AS t1(t5a, t5b, t5c)
-- !query schema
struct<>
-- !query output



-- !query
SELECT 
  ( SELECT max(t2b), min(t2b) 
    FROM t2 
    WHERE t2.t2b = t1.t1b
    GROUP BY t2.t2b
  )
FROM t1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "LEGACY",
  "messageParameters" : {
    "message" : "Scalar subquery must return only one column, but got 2;\nProject [scalar-subquery#x [t1b#x] AS scalarsubquery(t1b)#x]\n:  +- Aggregate [t2b#x], [max(t2b#x) AS max(t2b)#x, min(t2b#x) AS min(t2b)#x]\n:     +- Filter (t2b#x = outer(t1b#x))\n:        +- SubqueryAlias t2\n:           +- View (`t2`, [t2a#x,t2b#x,t2c#x])\n:              +- Project [cast(t2a#x as int) AS t2a#x, cast(t2b#x as int) AS t2b#x, cast(t2c#x as int) AS t2c#x]\n:                 +- Project [t2a#x, t2b#x, t2c#x]\n:                    +- SubqueryAlias t2\n:                       +- LocalRelation [t2a#x, t2b#x, t2c#x]\n+- SubqueryAlias t1\n   +- View (`t1`, [t1a#x,t1b#x,t1c#x])\n      +- Project [cast(t1a#x as int) AS t1a#x, cast(t1b#x as int) AS t1b#x, cast(t1c#x as int) AS t1c#x]\n         +- Project [t1a#x, t1b#x, t1c#x]\n            +- SubqueryAlias t1\n               +- LocalRelation [t1a#x, t1b#x, t1c#x]\n"
  }
}


-- !query
SELECT 
  ( SELECT max(t2b), min(t2b) 
    FROM t2 
    WHERE t2.t2b > 0
    GROUP BY t2.t2b
  )
FROM t1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "LEGACY",
  "messageParameters" : {
    "message" : "Scalar subquery must return only one column, but got 2;\nProject [scalar-subquery#x [] AS scalarsubquery()#x]\n:  +- Aggregate [t2b#x], [max(t2b#x) AS max(t2b)#x, min(t2b#x) AS min(t2b)#x]\n:     +- Filter (t2b#x > 0)\n:        +- SubqueryAlias t2\n:           +- View (`t2`, [t2a#x,t2b#x,t2c#x])\n:              +- Project [cast(t2a#x as int) AS t2a#x, cast(t2b#x as int) AS t2b#x, cast(t2c#x as int) AS t2c#x]\n:                 +- Project [t2a#x, t2b#x, t2c#x]\n:                    +- SubqueryAlias t2\n:                       +- LocalRelation [t2a#x, t2b#x, t2c#x]\n+- SubqueryAlias t1\n   +- View (`t1`, [t1a#x,t1b#x,t1c#x])\n      +- Project [cast(t1a#x as int) AS t1a#x, cast(t1b#x as int) AS t1b#x, cast(t1c#x as int) AS t1c#x]\n         +- Project [t1a#x, t1b#x, t1c#x]\n            +- SubqueryAlias t1\n               +- LocalRelation [t1a#x, t1b#x, t1c#x]\n"
  }
}


-- !query
SELECT * FROM t1
WHERE
t1a IN (SELECT t2a, t2b 
        FROM t2
        WHERE t1a = t2a)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "LEGACY",
  "messageParameters" : {
    "message" : "cannot resolve '(t1.t1a IN (listquery(t1.t1a)))' due to data type mismatch: \nThe number of columns in the left hand side of an IN subquery does not match the\nnumber of columns in the output of subquery.\n#columns in left hand side: 1.\n#columns in right hand side: 2.\nLeft side columns:\n[t1.t1a].\nRight side columns:\n[t2.t2a, t2.t2b].; line 3 pos 4;\n'Project [*]\n+- 'Filter t1a#x IN (list#x [t1a#x])\n   :  +- Project [t2a#x, t2b#x]\n   :     +- Filter (outer(t1a#x) = t2a#x)\n   :        +- SubqueryAlias t2\n   :           +- View (`t2`, [t2a#x,t2b#x,t2c#x])\n   :              +- Project [cast(t2a#x as int) AS t2a#x, cast(t2b#x as int) AS t2b#x, cast(t2c#x as int) AS t2c#x]\n   :                 +- Project [t2a#x, t2b#x, t2c#x]\n   :                    +- SubqueryAlias t2\n   :                       +- LocalRelation [t2a#x, t2b#x, t2c#x]\n   +- SubqueryAlias t1\n      +- View (`t1`, [t1a#x,t1b#x,t1c#x])\n         +- Project [cast(t1a#x as int) AS t1a#x, cast(t1b#x as int) AS t1b#x, cast(t1c#x as int) AS t1c#x]\n            +- Project [t1a#x, t1b#x, t1c#x]\n               +- SubqueryAlias t1\n                  +- LocalRelation [t1a#x, t1b#x, t1c#x]\n"
  }
}


-- !query
SELECT * FROM T1 
WHERE
(t1a, t1b) IN (SELECT t2a
               FROM t2
               WHERE t1a = t2a)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "LEGACY",
  "messageParameters" : {
    "message" : "cannot resolve '(named_struct('t1a', t1.t1a, 't1b', t1.t1b) IN (listquery(t1.t1a)))' due to data type mismatch: \nThe number of columns in the left hand side of an IN subquery does not match the\nnumber of columns in the output of subquery.\n#columns in left hand side: 2.\n#columns in right hand side: 1.\nLeft side columns:\n[t1.t1a, t1.t1b].\nRight side columns:\n[t2.t2a].; line 3 pos 11;\n'Project [*]\n+- 'Filter named_struct(t1a, t1a#x, t1b, t1b#x) IN (list#x [t1a#x])\n   :  +- Project [t2a#x]\n   :     +- Filter (outer(t1a#x) = t2a#x)\n   :        +- SubqueryAlias t2\n   :           +- View (`t2`, [t2a#x,t2b#x,t2c#x])\n   :              +- Project [cast(t2a#x as int) AS t2a#x, cast(t2b#x as int) AS t2b#x, cast(t2c#x as int) AS t2c#x]\n   :                 +- Project [t2a#x, t2b#x, t2c#x]\n   :                    +- SubqueryAlias t2\n   :                       +- LocalRelation [t2a#x, t2b#x, t2c#x]\n   +- SubqueryAlias t1\n      +- View (`t1`, [t1a#x,t1b#x,t1c#x])\n         +- Project [cast(t1a#x as int) AS t1a#x, cast(t1b#x as int) AS t1b#x, cast(t1c#x as int) AS t1c#x]\n            +- Project [t1a#x, t1b#x, t1c#x]\n               +- SubqueryAlias t1\n                  +- LocalRelation [t1a#x, t1b#x, t1c#x]\n"
  }
}


-- !query
SELECT * FROM t4
WHERE
(t4a, t4b, t4c) IN (SELECT t5a,
                           t5b,
                           t5c
                    FROM t5)
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
{
  "errorClass" : "LEGACY",
  "messageParameters" : {
    "message" : "cannot resolve '(named_struct('t4a', t4.t4a, 't4b', t4.t4b, 't4c', t4.t4c) IN (listquery()))' due to data type mismatch: \nThe data type of one or more elements in the left hand side of an IN subquery\nis not compatible with the data type of the output of the subquery\nMismatched columns:\n[(t4.t4a:double, t5.t5a:timestamp), (t4.t4c:string, t5.t5c:bigint)]\nLeft side:\n[double, string, string].\nRight side:\n[timestamp, string, bigint].; line 3 pos 16;\n'Project [*]\n+- 'Filter named_struct(t4a, t4a#x, t4b, t4b#x, t4c, t4c#x) IN (list#x [])\n   :  +- Project [t5a#x, t5b#x, t5c#xL]\n   :     +- SubqueryAlias t5\n   :        +- View (`t5`, [t5a#x,t5b#x,t5c#xL])\n   :           +- Project [cast(t5a#x as timestamp) AS t5a#x, cast(t5b#x as string) AS t5b#x, cast(t5c#xL as bigint) AS t5c#xL]\n   :              +- Project [t5a#x, t5b#x, t5c#xL]\n   :                 +- SubqueryAlias t1\n   :                    +- LocalRelation [t5a#x, t5b#x, t5c#xL]\n   +- SubqueryAlias t4\n      +- View (`t4`, [t4a#x,t4b#x,t4c#x])\n         +- Project [cast(t4a#x as double) AS t4a#x, cast(t4b#x as string) AS t4b#x, cast(t4c#x as string) AS t4c#x]\n            +- Project [t4a#x, t4b#x, t4c#x]\n               +- SubqueryAlias t1\n                  +- LocalRelation [t4a#x, t4b#x, t4c#x]\n"
  }
}
